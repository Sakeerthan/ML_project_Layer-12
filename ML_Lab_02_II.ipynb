{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599d768a-31b5-42dc-88e2-99cd590bd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5a6e88-6968-4f80-8a48-9369ef2171b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d3fe85-0650-49b9-b7c4-6dada8f6c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.099683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085248</td>\n",
       "      <td>-0.096007</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>-0.041432</td>\n",
       "      <td>0.094806</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.175731</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.196254</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>-0.239192</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090283</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>-0.122958</td>\n",
       "      <td>0.192949</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.160776</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>-0.050092</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.173831</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.065046</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071936</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>-0.121892</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>-0.065965</td>\n",
       "      <td>-0.088732</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155621</td>\n",
       "      <td>-0.079447</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-0.151966</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.031138   0.079892   0.157382  -0.014636  -0.051778  -0.021332   \n",
       "1   0.113040   0.175731   0.217741  -0.196254  -0.010129  -0.030586   \n",
       "2   0.048570   0.091281   0.160776  -0.150937   0.020115   0.044117   \n",
       "3   0.039212   0.118388   0.173831  -0.096659  -0.008702   0.061298   \n",
       "4   0.056019   0.170639   0.157917  -0.228605  -0.065965  -0.088732   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0  -0.073593  -0.005386  -0.212557    0.099683  ...    -0.085248    -0.096007   \n",
       "1   0.067114  -0.072412  -0.239192    0.104741  ...    -0.090283    -0.053885   \n",
       "2  -0.050092  -0.045661  -0.155332    0.117206  ...    -0.021524    -0.008411   \n",
       "3   0.008974  -0.003277  -0.065046    0.095480  ...    -0.071936    -0.023120   \n",
       "4  -0.082243  -0.080568  -0.341500    0.142430  ...    -0.155621    -0.079447   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.000766     0.021399    -0.041432     0.094806       45      NaN   \n",
       "1    -0.010967     0.062209    -0.122958     0.192949       45      NaN   \n",
       "2    -0.006248     0.031468    -0.056915     0.154731       45      NaN   \n",
       "3    -0.007812     0.057600    -0.121892     0.072796       45      NaN   \n",
       "4     0.015316     0.127726    -0.151966     0.169634       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320353c1-7193-4847-8241-4bfa1477bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1        0\n",
       "feature_2        0\n",
       "feature_3        0\n",
       "feature_4        0\n",
       "feature_5        0\n",
       "              ... \n",
       "feature_768      0\n",
       "label_1          0\n",
       "label_2        480\n",
       "label_3          0\n",
       "label_4          0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84086ca-ee0b-4f3d-a77d-2aaa80b937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_train = df.drop(y_train, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4f5417-46a0-4e3b-a090-8ee8c68c8716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031138</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.021332</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.099683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085613</td>\n",
       "      <td>0.116276</td>\n",
       "      <td>-0.009873</td>\n",
       "      <td>-0.168441</td>\n",
       "      <td>-0.085248</td>\n",
       "      <td>-0.096007</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>-0.041432</td>\n",
       "      <td>0.094806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.175731</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.196254</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.030586</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>-0.239192</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235261</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>-0.318012</td>\n",
       "      <td>-0.090283</td>\n",
       "      <td>-0.053885</td>\n",
       "      <td>-0.010967</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>-0.122958</td>\n",
       "      <td>0.192949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048570</td>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.160776</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>-0.050092</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.155332</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146143</td>\n",
       "      <td>0.113063</td>\n",
       "      <td>0.038823</td>\n",
       "      <td>-0.199746</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>0.154731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.173831</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.065046</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102543</td>\n",
       "      <td>0.101914</td>\n",
       "      <td>0.043303</td>\n",
       "      <td>-0.202432</td>\n",
       "      <td>-0.071936</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>-0.121892</td>\n",
       "      <td>0.072796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.157917</td>\n",
       "      <td>-0.228605</td>\n",
       "      <td>-0.065965</td>\n",
       "      <td>-0.088732</td>\n",
       "      <td>-0.082243</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>0.142430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253095</td>\n",
       "      <td>0.131308</td>\n",
       "      <td>0.089454</td>\n",
       "      <td>-0.219729</td>\n",
       "      <td>-0.155621</td>\n",
       "      <td>-0.079447</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-0.151966</td>\n",
       "      <td>0.169634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.076411</td>\n",
       "      <td>0.105938</td>\n",
       "      <td>-0.112908</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.059527</td>\n",
       "      <td>-0.079593</td>\n",
       "      <td>-0.073753</td>\n",
       "      <td>-0.107601</td>\n",
       "      <td>0.104177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134283</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.041743</td>\n",
       "      <td>-0.128696</td>\n",
       "      <td>0.044550</td>\n",
       "      <td>-0.056263</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.075623</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.240886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.025557</td>\n",
       "      <td>0.071350</td>\n",
       "      <td>-0.041278</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>-0.028207</td>\n",
       "      <td>-0.031185</td>\n",
       "      <td>-0.054272</td>\n",
       "      <td>0.029009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027247</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>-0.069785</td>\n",
       "      <td>0.025501</td>\n",
       "      <td>-0.018314</td>\n",
       "      <td>-0.012793</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>0.046191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.065977</td>\n",
       "      <td>-0.035693</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>-0.022635</td>\n",
       "      <td>-0.041316</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>-0.052741</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>-0.011894</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>-0.004554</td>\n",
       "      <td>0.061891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>0.035765</td>\n",
       "      <td>0.053481</td>\n",
       "      <td>0.131675</td>\n",
       "      <td>-0.043579</td>\n",
       "      <td>-0.011288</td>\n",
       "      <td>-0.002910</td>\n",
       "      <td>-0.042682</td>\n",
       "      <td>-0.006227</td>\n",
       "      <td>-0.107985</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.056293</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>-0.112201</td>\n",
       "      <td>-0.011463</td>\n",
       "      <td>-0.035990</td>\n",
       "      <td>-0.018325</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>-0.020396</td>\n",
       "      <td>0.050323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.041245</td>\n",
       "      <td>0.101223</td>\n",
       "      <td>-0.047161</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>-0.052609</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.051188</td>\n",
       "      <td>0.023919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016804</td>\n",
       "      <td>0.037677</td>\n",
       "      <td>0.039298</td>\n",
       "      <td>-0.089907</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>-0.025880</td>\n",
       "      <td>0.064083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28520 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0       0.031138   0.079892   0.157382  -0.014636  -0.051778  -0.021332   \n",
       "1       0.113040   0.175731   0.217741  -0.196254  -0.010129  -0.030586   \n",
       "2       0.048570   0.091281   0.160776  -0.150937   0.020115   0.044117   \n",
       "3       0.039212   0.118388   0.173831  -0.096659  -0.008702   0.061298   \n",
       "4       0.056019   0.170639   0.157917  -0.228605  -0.065965  -0.088732   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "28515   0.051860   0.076411   0.105938  -0.112908   0.023364   0.059527   \n",
       "28516   0.015274   0.025557   0.071350  -0.041278  -0.010443   0.009135   \n",
       "28517  -0.000337   0.029920   0.065977  -0.035693   0.018643  -0.000174   \n",
       "28518   0.035765   0.053481   0.131675  -0.043579  -0.011288  -0.002910   \n",
       "28519   0.004939   0.041245   0.101223  -0.047161   0.007973  -0.006654   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
       "0      -0.073593  -0.005386  -0.212557    0.099683  ...    -0.085613   \n",
       "1       0.067114  -0.072412  -0.239192    0.104741  ...    -0.235261   \n",
       "2      -0.050092  -0.045661  -0.155332    0.117206  ...    -0.146143   \n",
       "3       0.008974  -0.003277  -0.065046    0.095480  ...    -0.102543   \n",
       "4      -0.082243  -0.080568  -0.341500    0.142430  ...    -0.253095   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "28515  -0.079593  -0.073753  -0.107601    0.104177  ...    -0.134283   \n",
       "28516  -0.028207  -0.031185  -0.054272    0.029009  ...     0.027247   \n",
       "28517  -0.051270  -0.022635  -0.041316    0.001559  ...     0.002205   \n",
       "28518  -0.042682  -0.006227  -0.107985    0.055559  ...     0.004783   \n",
       "28519  -0.052609  -0.001305  -0.051188    0.023919  ...    -0.016804   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.116276    -0.009873    -0.168441    -0.085248    -0.096007   \n",
       "1         0.075487     0.032231    -0.318012    -0.090283    -0.053885   \n",
       "2         0.113063     0.038823    -0.199746    -0.021524    -0.008411   \n",
       "3         0.101914     0.043303    -0.202432    -0.071936    -0.023120   \n",
       "4         0.131308     0.089454    -0.219729    -0.155621    -0.079447   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "28515     0.084795     0.041743    -0.128696     0.044550    -0.056263   \n",
       "28516     0.021062     0.025761    -0.069785     0.025501    -0.018314   \n",
       "28517     0.030578     0.007359    -0.052741     0.038724    -0.011894   \n",
       "28518     0.056293     0.019945    -0.112201    -0.011463    -0.035990   \n",
       "28519     0.037677     0.039298    -0.089907     0.020371    -0.009467   \n",
       "\n",
       "       feature_765  feature_766  feature_767  feature_768  \n",
       "0        -0.000766     0.021399    -0.041432     0.094806  \n",
       "1        -0.010967     0.062209    -0.122958     0.192949  \n",
       "2        -0.006248     0.031468    -0.056915     0.154731  \n",
       "3        -0.007812     0.057600    -0.121892     0.072796  \n",
       "4         0.015316     0.127726    -0.151966     0.169634  \n",
       "...            ...          ...          ...          ...  \n",
       "28515     0.004664     0.075623     0.017195     0.240886  \n",
       "28516    -0.012793     0.000299     0.012029     0.046191  \n",
       "28517     0.002687     0.008560    -0.004554     0.061891  \n",
       "28518    -0.018325    -0.010334    -0.020396     0.050323  \n",
       "28519    -0.001557     0.019498    -0.025880     0.064083  \n",
       "\n",
       "[28520 rows x 768 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727b29dc-1122-4c65-95ab-6280829e5a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28520 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_1  label_2  label_3  label_4\n",
       "0           45      NaN        1        6\n",
       "1           45      NaN        1        6\n",
       "2           45      NaN        1        6\n",
       "3           45      NaN        1        6\n",
       "4           45      NaN        1        6\n",
       "...        ...      ...      ...      ...\n",
       "28515       39     29.0        1        6\n",
       "28516       39     29.0        1        6\n",
       "28517       39     29.0        1        6\n",
       "28518       39     29.0        1        6\n",
       "28519       39     29.0        1        6\n",
       "\n",
       "[28520 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15f069-d371-4542-9a96-3807c6decbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9866970b-8b1b-40af-ae8d-671f9543a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c2ab19-1c81-4076-b8ab-173c085d3f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153978</td>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>0.226684</td>\n",
       "      <td>0.466179</td>\n",
       "      <td>0.154995</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>-0.288972</td>\n",
       "      <td>-0.297589</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503624</td>\n",
       "      <td>-0.056849</td>\n",
       "      <td>-0.117077</td>\n",
       "      <td>0.168611</td>\n",
       "      <td>0.373346</td>\n",
       "      <td>0.037188</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.261613</td>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>-0.011609</td>\n",
       "      <td>0.201331</td>\n",
       "      <td>-0.194763</td>\n",
       "      <td>-0.194228</td>\n",
       "      <td>-0.094267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442110</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>-0.067920</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.333104</td>\n",
       "      <td>-0.270913</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225439</td>\n",
       "      <td>0.350977</td>\n",
       "      <td>-0.295782</td>\n",
       "      <td>0.280168</td>\n",
       "      <td>0.705114</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.390878</td>\n",
       "      <td>-0.322853</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380124</td>\n",
       "      <td>-0.089572</td>\n",
       "      <td>-0.023344</td>\n",
       "      <td>0.194312</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>-0.292029</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288556</td>\n",
       "      <td>0.513905</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>0.279660</td>\n",
       "      <td>0.469121</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>0.131205</td>\n",
       "      <td>-0.338951</td>\n",
       "      <td>-0.270848</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529678</td>\n",
       "      <td>-0.093194</td>\n",
       "      <td>-0.148418</td>\n",
       "      <td>0.405543</td>\n",
       "      <td>0.438906</td>\n",
       "      <td>-0.055119</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165176</td>\n",
       "      <td>0.312492</td>\n",
       "      <td>-0.217504</td>\n",
       "      <td>0.259960</td>\n",
       "      <td>0.568979</td>\n",
       "      <td>-0.093011</td>\n",
       "      <td>0.257977</td>\n",
       "      <td>-0.277132</td>\n",
       "      <td>-0.172113</td>\n",
       "      <td>-0.025929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504997</td>\n",
       "      <td>-0.108256</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.267815</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.153978   0.503276   0.022196   0.226684   0.466179   0.154995   \n",
       "1   0.056877   0.261613   0.050610   0.097744   0.322375  -0.011609   \n",
       "2   0.225439   0.350977  -0.295782   0.280168   0.705114   0.020545   \n",
       "3   0.288556   0.513905  -0.205246   0.279660   0.469121   0.068339   \n",
       "4   0.165176   0.312492  -0.217504   0.259960   0.568979  -0.093011   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0   0.195452  -0.288972  -0.297589   -0.008409  ...    -0.503624    -0.056849   \n",
       "1   0.201331  -0.194763  -0.194228   -0.094267  ...    -0.442110     0.008424   \n",
       "2   0.390878  -0.322853   0.071575    0.013803  ...    -0.380124    -0.089572   \n",
       "3   0.131205  -0.338951  -0.270848    0.007799  ...    -0.529678    -0.093194   \n",
       "4   0.257977  -0.277132  -0.172113   -0.025929  ...    -0.504997    -0.108256   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0    -0.117077     0.168611     0.373346     0.037188       45      NaN   \n",
       "1    -0.067920     0.165600     0.333104    -0.270913       45      NaN   \n",
       "2    -0.023344     0.194312     0.269537    -0.292029       45      NaN   \n",
       "3    -0.148418     0.405543     0.438906    -0.055119       45      NaN   \n",
       "4     0.036867     0.267815     0.245041     0.117444       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6bbf21f-103e-4787-94f7-f1446bf4c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1       0\n",
       "feature_2       0\n",
       "feature_3       0\n",
       "feature_4       0\n",
       "feature_5       0\n",
       "               ..\n",
       "feature_768     0\n",
       "label_1         0\n",
       "label_2        14\n",
       "label_3         0\n",
       "label_4         0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2d1465-c851-4d91-876c-e8dd9a3f645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_df[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_valid = valid_df.drop(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81814549-3231-48d5-bbdf-00de25859801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153978</td>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>0.226684</td>\n",
       "      <td>0.466179</td>\n",
       "      <td>0.154995</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>-0.288972</td>\n",
       "      <td>-0.297589</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058990</td>\n",
       "      <td>-0.112258</td>\n",
       "      <td>-0.128763</td>\n",
       "      <td>-0.243036</td>\n",
       "      <td>-0.503624</td>\n",
       "      <td>-0.056849</td>\n",
       "      <td>-0.117077</td>\n",
       "      <td>0.168611</td>\n",
       "      <td>0.373346</td>\n",
       "      <td>0.037188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.261613</td>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>-0.011609</td>\n",
       "      <td>0.201331</td>\n",
       "      <td>-0.194763</td>\n",
       "      <td>-0.194228</td>\n",
       "      <td>-0.094267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>0.033275</td>\n",
       "      <td>-0.042320</td>\n",
       "      <td>-0.012359</td>\n",
       "      <td>-0.442110</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>-0.067920</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.333104</td>\n",
       "      <td>-0.270913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225439</td>\n",
       "      <td>0.350977</td>\n",
       "      <td>-0.295782</td>\n",
       "      <td>0.280168</td>\n",
       "      <td>0.705114</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>0.390878</td>\n",
       "      <td>-0.322853</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039573</td>\n",
       "      <td>-0.063131</td>\n",
       "      <td>-0.180942</td>\n",
       "      <td>-0.146527</td>\n",
       "      <td>-0.380124</td>\n",
       "      <td>-0.089572</td>\n",
       "      <td>-0.023344</td>\n",
       "      <td>0.194312</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>-0.292029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288556</td>\n",
       "      <td>0.513905</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>0.279660</td>\n",
       "      <td>0.469121</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>0.131205</td>\n",
       "      <td>-0.338951</td>\n",
       "      <td>-0.270848</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>-0.037250</td>\n",
       "      <td>-0.242656</td>\n",
       "      <td>-0.287592</td>\n",
       "      <td>-0.529678</td>\n",
       "      <td>-0.093194</td>\n",
       "      <td>-0.148418</td>\n",
       "      <td>0.405543</td>\n",
       "      <td>0.438906</td>\n",
       "      <td>-0.055119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165176</td>\n",
       "      <td>0.312492</td>\n",
       "      <td>-0.217504</td>\n",
       "      <td>0.259960</td>\n",
       "      <td>0.568979</td>\n",
       "      <td>-0.093011</td>\n",
       "      <td>0.257977</td>\n",
       "      <td>-0.277132</td>\n",
       "      <td>-0.172113</td>\n",
       "      <td>-0.025929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181833</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.039907</td>\n",
       "      <td>-0.410866</td>\n",
       "      <td>-0.504997</td>\n",
       "      <td>-0.108256</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.267815</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>0.117444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.153978   0.503276   0.022196   0.226684   0.466179   0.154995   \n",
       "1   0.056877   0.261613   0.050610   0.097744   0.322375  -0.011609   \n",
       "2   0.225439   0.350977  -0.295782   0.280168   0.705114   0.020545   \n",
       "3   0.288556   0.513905  -0.205246   0.279660   0.469121   0.068339   \n",
       "4   0.165176   0.312492  -0.217504   0.259960   0.568979  -0.093011   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0   0.195452  -0.288972  -0.297589   -0.008409  ...     0.058990    -0.112258   \n",
       "1   0.201331  -0.194763  -0.194228   -0.094267  ...    -0.002137     0.033275   \n",
       "2   0.390878  -0.322853   0.071575    0.013803  ...    -0.039573    -0.063131   \n",
       "3   0.131205  -0.338951  -0.270848    0.007799  ...     0.027014    -0.037250   \n",
       "4   0.257977  -0.277132  -0.172113   -0.025929  ...     0.181833    -0.006872   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0    -0.128763    -0.243036    -0.503624    -0.056849    -0.117077   \n",
       "1    -0.042320    -0.012359    -0.442110     0.008424    -0.067920   \n",
       "2    -0.180942    -0.146527    -0.380124    -0.089572    -0.023344   \n",
       "3    -0.242656    -0.287592    -0.529678    -0.093194    -0.148418   \n",
       "4    -0.039907    -0.410866    -0.504997    -0.108256     0.036867   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.168611     0.373346     0.037188  \n",
       "1     0.165600     0.333104    -0.270913  \n",
       "2     0.194312     0.269537    -0.292029  \n",
       "3     0.405543     0.438906    -0.055119  \n",
       "4     0.267815     0.245041     0.117444  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "890b0c91-da90-4756-bca6-95decbec1b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_1  label_2  label_3  label_4\n",
       "0       45      NaN        1        6\n",
       "1       45      NaN        1        6\n",
       "2       45      NaN        1        6\n",
       "3       45      NaN        1        6\n",
       "4       45      NaN        1        6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd41b8-3fc2-4c1c-bcfa-efd2ac3a7959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbb792-8d52-42f9-ac9b-0032628c9850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe69d98c-48e9-4f14-9fa9-46cdcea624e0",
   "metadata": {},
   "source": [
    "# KNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2760f1-9555-4a0f-bb53-43da1995bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_knn(train_x, train_y, valid_x, valid_y):\n",
    "    grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "    g_res = gs.fit(train_x, train_y)\n",
    "    print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "    # Get the best k-NN model with the optimal hyperparameters\n",
    "    best_knn = gs.best_estimator_\n",
    "    # Evaluate the best model on the test data\n",
    "    accuracy = best_knn.score(valid_x, valid_y)\n",
    "    print(f\"Accuracy for KNN {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e8bb6-1c2e-4bab-b2db-b993763f6085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b98508b-b0fb-4880-ab33-83c53c5d0853",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b9bfeb-e45a-471d-96c2-526fa6852c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_svm(train_x, train_y, valid_x, valid_y):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with default settings (RBF - exponential kernal) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.LinearSVC(dual=\"auto\")\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of Linear SVM (one-vs-the-rest) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with linear kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with sigmoid kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 2 \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 3 \", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa91d6-d63c-4f46-8a44-0385f12de849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc269b21-4ab2-4655-a766-2c1bf8cdd7e1",
   "metadata": {},
   "source": [
    "# xgBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b935109-4c73-4b95-9310-a61ed6843def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def try_xgBoost(train_x, train_y, vaid_x, valid_y):\n",
    "    # Create an XGBoost classifier for multi-class classification\n",
    "    clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(train_y)),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(train_y)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    print(f\"Accuracy Score of XG Boost\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f0c01-f889-4b0b-a29c-c136440df249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0ea55a-9e12-4ab5-85fc-c91fd8f90fa6",
   "metadata": {},
   "source": [
    "# Rondom Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "339cfddd-ec25-46f0-83cb-c2868075ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def try_random_forest(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Random Forest\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254adbc-16e3-4dcf-8900-9ecb7b609568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41067ebd-5553-4e1d-8673-c20ec661ca6c",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01972a52-f57d-4cdd-a7bb-90f1c06ea008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def try_logistic(train_x, train_y, vaid_x, valid_y):\n",
    "    for i in [\"lbfgs\",\"newton-cg\",\"sag\",\"saga\"]:\n",
    "        logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        logistic_regression.fit(train_x,train_y)\n",
    "        y_pred = logistic_regression.predict(vaid_x)\n",
    "        print(f\"Accuracy Score of Logistic Regression with solver {i}\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4b11b-0cee-4c37-a009-8d7bb293bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b77901-b66c-442d-accb-47034087bd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4df941a9-fa5a-431c-909f-3d605fb9b803",
   "metadata": {},
   "source": [
    "# Predict a probability for the TARGET variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380dec34-505f-4095-88d7-12c7ef05caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   1   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   2   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   3   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   4   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   5   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73446afd-292d-4ce0-bd69-13ce9a0187a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c686240-5a9a-4a22-aee2-e6745a0c10d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.257004</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>-0.054916</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.035149</td>\n",
       "      <td>-0.092019</td>\n",
       "      <td>-0.196302</td>\n",
       "      <td>0.077971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221466</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>-0.175572</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.087621</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.139337</td>\n",
       "      <td>-0.083030</td>\n",
       "      <td>0.059507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.227644</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>-0.044476</td>\n",
       "      <td>-0.046852</td>\n",
       "      <td>-0.090026</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>-0.227288</td>\n",
       "      <td>0.066863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204930</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.113195</td>\n",
       "      <td>-0.057312</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>-0.096283</td>\n",
       "      <td>0.042701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032937</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>-0.149850</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.017069</td>\n",
       "      <td>0.048123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.352175</td>\n",
       "      <td>-0.108499</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.073239</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.342217</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.215386</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.035071</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.067768</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.174444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>-0.016143</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>-0.055789</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.060278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035814</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>-0.116009</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.042293</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>-0.007731</td>\n",
       "      <td>0.058799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.124623   0.196628   0.257004  -0.156045  -0.054916   0.006071   \n",
       "1   0.109655   0.170158   0.227644  -0.127088  -0.044476  -0.046852   \n",
       "2   0.014854   0.030051   0.115092  -0.017179   0.002720  -0.011692   \n",
       "3   0.196893   0.113314   0.352175  -0.108499  -0.064472  -0.073239   \n",
       "4   0.033004   0.013373   0.124001  -0.016143   0.010120   0.010635   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0  -0.035149  -0.092019  -0.196302    0.077971  ...    -0.221466     0.140292   \n",
       "1  -0.090026  -0.061321  -0.227288    0.066863  ...    -0.204930     0.110203   \n",
       "2  -0.078855  -0.042991  -0.096283    0.042701  ...    -0.032937     0.075821   \n",
       "3  -0.086402   0.008671  -0.342217    0.104941  ...    -0.255167     0.096579   \n",
       "4  -0.055789  -0.036282  -0.059422    0.060278  ...    -0.035814     0.093764   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.123622    -0.175572    -0.107030    -0.087621    -0.026501   \n",
       "1     0.085665    -0.286787    -0.113195    -0.057312    -0.055680   \n",
       "2     0.030987    -0.149850    -0.003155    -0.010207    -0.001427   \n",
       "3     0.069413    -0.215386    -0.075168    -0.035071    -0.023375   \n",
       "4     0.027321    -0.116009     0.010096    -0.042293     0.005347   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.139337    -0.083030     0.059507  \n",
       "1     0.143939    -0.045760     0.106113  \n",
       "2     0.000934    -0.017069     0.048123  \n",
       "3     0.067768    -0.181530     0.174444  \n",
       "4     0.007722    -0.007731     0.058799  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b571355-0340-4f6a-bff0-45d0be659a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_764    0\n",
       "feature_765    0\n",
       "feature_766    0\n",
       "feature_767    0\n",
       "feature_768    0\n",
       "Length: 768, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a3937-37b0-48ce-ae32-158e2dfa27b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a5327e-712e-490c-92e3-7d46a8dc360e",
   "metadata": {},
   "source": [
    "# Label_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e132e3-162e-4000-b2cf-bbefb7edc3e5",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "352159dc-4a4a-45ff-84eb-4f26cad7c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.06266666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.07733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.212\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a5454-54c0-4592-84c3-2ccec74616ad",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab99291a-4537-4bf3-b1df-9c51fac3f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.24266666666666667\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7581c08-ce0d-4107-bf13-8b738828afa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeed95cb-fbff-4455-8123-35cb2a8e7ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.06933333333333333\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbcba9-34ce-46b4-8323-041b77cb699b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "feb548d5-b899-4a5e-9958-60e56dd0d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.06133333333333333\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a97af6-c07b-4f6b-ad88-d31ca88a7e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b49154e8-1018-4c29-8233-7db91500a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.15066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.15066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.15066666666666667\n",
      "Accuracy Score of Logistic Regression with solver saga 0.15066666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7ed0c-b1eb-42aa-a437-369236fdbdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930ade8-8324-4c4b-9ea3-dc73273be04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d22a9-e985-47a7-8ebb-fa11b7a19951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381bc71-50c9-4faf-a913-b0d63aad2d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9140d3-1551-4297-b7c3-4294ed1c7643",
   "metadata": {},
   "source": [
    "# For label_1 we get best accuracy(0.24266) when using the KNN Model\n",
    "So we can use this method to predict the values for test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac583264-13a0-45c8-9feb-fbdee7a7c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26, 18, 16,  7, 58, 46,  7, 22, 29, 26, 33, 32, 54, 51, 17, 48, 23,\n",
       "        2, 43, 42, 11, 35, 39,  2, 21, 13, 28, 55,  2, 51, 55, 16,  1, 56,\n",
       "       30, 22, 31,  6, 24, 18,  5, 47,  6, 46, 59, 25, 31, 18,  5, 32, 25,\n",
       "       56, 39, 37, 32, 40,  5, 52, 28, 34,  2, 47, 55, 24, 23, 18, 20,  6,\n",
       "       36, 13, 22, 26, 44, 46, 55, 36, 49, 25, 57, 12, 52, 38, 23,  4, 33,\n",
       "        1, 14, 19, 12, 39, 36, 43, 34, 32, 54, 46, 27,  5,  7, 42, 19, 26,\n",
       "       31, 36, 53, 10, 12, 38, 38,  2, 57,  4,  7, 50, 46, 46, 17, 34, 30,\n",
       "       40, 16, 40,  8, 22, 38, 15, 13,  9, 52,  5, 40, 13, 10, 55, 28, 25,\n",
       "       42, 57, 16, 27, 51,  5, 51, 27, 32, 33, 16,  3, 11, 23, 42, 37, 47,\n",
       "       50,  3, 48, 19, 20, 15,  8,  5, 18,  5, 28, 46, 23, 50, 40,  1, 32,\n",
       "       24, 57, 42, 16, 11, 35, 34, 52, 41, 20,  7,  8, 21,  4, 37, 55, 20,\n",
       "       28, 23, 35, 46, 52, 30, 27,  1,  7, 28,  5,  3,  1, 17, 60,  3,  3,\n",
       "       22,  9, 24, 25, 17, 26, 19, 36, 36, 21,  1, 58, 31, 47, 38,  6, 50,\n",
       "       39, 23,  5, 48, 22, 58, 15, 30, 38, 18, 54,  8, 41, 16,  8, 23, 21,\n",
       "        8, 52, 10, 16, 47, 20, 15, 51, 56, 11, 16, 33, 50, 51, 10, 51, 31,\n",
       "        6,  9, 31, 57, 22,  5, 11, 11, 43,  8,  7, 58, 23, 50, 58,  6, 13,\n",
       "       47, 50, 60, 50, 47, 36, 28, 36, 10, 39, 34, 32,  5,  2, 19, 31, 57,\n",
       "       50, 30, 32, 41, 37, 41, 51, 20, 20, 24, 21, 44, 31, 15, 40, 46,  6,\n",
       "       21, 25, 29, 44, 54, 34, 46, 57, 26, 53, 26,  8, 17,  5, 31, 12,  8,\n",
       "       32, 59, 49, 56, 17, 26, 49, 54, 10,  9,  3, 36, 39, 33, 16, 54, 29,\n",
       "       23, 10, 11, 47, 37, 33,  4, 35, 25, 27,  4, 51, 12, 33, 42, 33, 44,\n",
       "       23,  6, 12, 30, 40, 56, 24,  8, 44, 15,  3, 38, 39, 29, 28,  7, 15,\n",
       "        3,  5, 37, 17,  3, 60, 58,  9, 10, 31, 60, 23,  7, 15, 18,  7, 11,\n",
       "       15,  2, 23, 41,  4, 29,  7, 40, 53, 42, 20, 21, 35, 31, 58,  6, 29,\n",
       "       52, 29, 31, 20,  1, 50, 28, 39, 50, 27, 20, 44, 24,  8, 38, 51, 37,\n",
       "       23,  8, 18, 11, 13,  8, 15, 23, 39, 11, 39, 31, 58, 60, 52, 30, 31,\n",
       "        5, 29, 33, 10, 48, 21, 51, 21, 37, 55, 19, 49, 60, 38, 28,  6, 17,\n",
       "       11, 40, 17, 30,  1,  4, 36, 30, 58, 57, 53, 18, 37, 52, 25, 14, 13,\n",
       "       13, 30, 41, 57, 25, 16, 43, 36, 13, 43, 23, 37, 29,  6,  8, 13, 53,\n",
       "       24, 13, 29, 31, 21, 13, 27,  5, 22, 22, 49,  9, 23, 56, 12, 30, 56,\n",
       "       24, 40, 32, 16, 37, 41, 26, 11, 42, 11, 36, 47, 23, 16, 29, 18, 47,\n",
       "       23, 22, 55, 27, 33,  3, 40, 40, 18, 31,  1,  7, 59, 28, 44, 29, 57,\n",
       "        3, 22, 37, 27, 34, 32, 57, 44, 37, 38,  2, 22, 33, 53, 31, 45,  1,\n",
       "       55,  7, 33, 48, 27, 48,  6, 24, 54, 26, 36, 15, 35, 17, 16,  4, 17,\n",
       "       27, 10, 12, 19,  6, 47, 21,  5, 48, 55, 16, 42,  6,  4, 24, 39, 16,\n",
       "       33, 43, 41,  1, 49, 46, 24, 40,  1, 19, 18, 43, 29, 57, 16, 25,  1,\n",
       "        2, 49, 59, 18,  8, 37, 32, 32, 57, 23, 25, 30, 26, 16, 10,  9, 12,\n",
       "       15, 11, 19, 37, 53, 19,  8, 17, 17,  4, 25, 22, 32, 27, 15,  3, 25,\n",
       "       50,  8, 20, 30, 13, 25, 60, 40, 11, 37,  2, 44, 31, 52, 31, 34,  2,\n",
       "       32, 24,  8, 54, 37, 43,  1, 32, 23, 51,  9, 32,  5, 30,  1, 46, 37,\n",
       "       19, 24, 38, 36,  6, 51, 20,  1, 51,  2, 58, 10, 42, 48, 11, 43, 39,\n",
       "        8, 50, 30, 15,  2,  9,  4, 22, 44, 16, 14, 31, 24, 37, 50,  1, 47,\n",
       "       19, 10,  5, 43, 21, 44, 48, 22, 33, 20, 23, 33, 46, 25, 51,  4, 54,\n",
       "       59, 28, 55, 50, 56, 26, 47, 16,  5, 35, 55, 38,  4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_model.fit(X_train, y_train[\"label_1\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label1 = knn_model.predict(X_test_contiguous)\n",
    "y_pred_label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf0bb2-8b35-4bad-a9d5-203a7000ac2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b6c68e-9088-4d69-a72d-e4edf48acf7b",
   "metadata": {},
   "source": [
    "# Label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76408354-4fde-411a-9be4-eb9bcd123d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_768    0\n",
       "label_1        0\n",
       "label_2        0\n",
       "label_3        0\n",
       "label_4        0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_2 = df.dropna(subset=['label_2'])\n",
    "df_label_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a3178f9-c94d-40ec-b896-f047cc2aad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_l2 = df_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_train_l2 = df_label_2.drop(y_train_l2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37dc7f16-ecc8-4657-ad02-e12fa408c4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_1  label_2  label_3  label_4\n",
       "480        5     25.0        1        6\n",
       "481        5     25.0        1        6\n",
       "482        5     25.0        1        6\n",
       "483        5     25.0        1        6\n",
       "484        5     25.0        1        6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3071d2bf-ed33-4a4a-9acb-0a577578df35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_768    0\n",
       "label_1        0\n",
       "label_2        0\n",
       "label_3        0\n",
       "label_4        0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_label_2 = valid_df.dropna(subset=['label_2'])\n",
    "valid_df_label_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38a2f501-f8f8-4b9d-845c-33f2a0695e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_l2 = valid_df_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_valid_l2 = valid_df_label_2.drop(y_train_l2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7568973e-41d5-42e1-ab78-280c6a7f8ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_1  label_2  label_3  label_4\n",
       "14        5     25.0        1        6\n",
       "15        5     25.0        1        6\n",
       "16        5     25.0        1        6\n",
       "17        5     25.0        1        6\n",
       "18        5     25.0        1        6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f6b86-0442-4f5a-bb42-56fd1bc28b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266fc800-6690-4b2a-afee-4918654d5525",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43bc0b-12b8-4d7e-bcca-d4d82f0a92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.12092391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.13994565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.13179347826086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.06521739130434782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.1480978260869565\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c6d15-7c72-40cc-a1f9-4af9a1e1ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e56c835-d47e-4010-a4cc-c013234334d4",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb979b72-1a93-4a71-b291-9177aec89f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.27445652173913043\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db35b2b-2216-4b64-8ed5-749caa3a80d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baea28bd-0ccb-4f7d-bb9a-9fcc22576dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.11413043478260869\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2635bf-ab37-4f90-9fa8-4fca3f260ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b6a5e4-afcf-48df-b3ec-42517a2c5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.12092391304347826\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347433d-8b36-4c9d-a673-40c600efbf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebfaf014-7e55-4744-894f-a02d3d349f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.17119565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.17119565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.17119565217391305\n",
      "Accuracy Score of Logistic Regression with solver saga 0.17119565217391305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cc7e6-cd5f-4e6b-81b1-d29372f8af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc249a5c-0f96-4134-b488-b5afc2b2b5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25319835-9274-42c9-a421-3a01049852b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbf54b-ac3d-4c8a-8879-3c15f2cfafd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257352c0-9e80-4636-a2d6-892d999af368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f63092a4-fc5b-4892-890d-fc306590d665",
   "metadata": {},
   "source": [
    "For label_4 we get best accuracy(0.27445) when using the KNN model. \n",
    "So we can use this methods to predict the values for test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e8ca8-16ea-4b9e-9c1f-a1e9ba85811b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a37f2751-2e88-4ae0-9297-e6a4c3040a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([22., 25., 30., 27., 29., 23., 27., 33., 23., 22., 26., 23., 27.,\n",
       "       26., 23., 26., 28., 25., 31., 29., 33., 24., 29., 25., 26., 22.,\n",
       "       28., 23., 25., 26., 23., 30., 30., 24., 28., 23., 26., 25., 26.,\n",
       "       25., 23., 23., 25., 30., 31., 22., 26., 25., 25., 23., 22., 24.,\n",
       "       29., 27., 23., 26., 24., 34., 28., 25., 23., 23., 23., 26., 28.,\n",
       "       25., 25., 25., 22., 23., 33., 22., 61., 30., 26., 22., 26., 22.,\n",
       "       27., 26., 34., 32., 28., 31., 26., 26., 31., 23., 26., 29., 22.,\n",
       "       31., 25., 23., 27., 30., 31., 25., 27., 29., 23., 22., 26., 22.,\n",
       "       24., 36., 26., 32., 32., 25., 27., 26., 26., 24., 30., 30., 26.,\n",
       "       25., 28., 26., 26., 26., 41., 33., 32., 28., 24., 35., 34., 25.,\n",
       "       26., 27., 36., 23., 28., 22., 29., 27., 30., 31., 26., 23., 22.,\n",
       "       31., 23., 26., 30., 23., 33., 24., 29., 27., 23., 24., 31., 26.,\n",
       "       23., 25., 28., 41., 25., 25., 25., 28., 30., 26., 24., 26., 26.,\n",
       "       23., 26., 27., 29., 30., 33., 24., 25., 34., 28., 23., 27., 41.,\n",
       "       26., 23., 27., 23., 25., 28., 28., 24., 30., 34., 28., 26., 30.,\n",
       "       27., 28., 25., 31., 22., 26., 27., 24., 31., 33., 35., 24., 22.,\n",
       "       26., 22., 23., 22., 22., 26., 30., 30., 29., 23., 26., 25., 24.,\n",
       "       29., 28., 25., 26., 33., 29., 28., 28., 32., 25., 27., 41., 30.,\n",
       "       30., 41., 31., 26., 41., 24., 36., 30., 23., 25., 28., 26., 24.,\n",
       "       33., 30., 26., 24., 26., 28., 26., 26., 25., 35., 26., 27., 33.,\n",
       "       25., 33., 33., 31., 41., 27., 29., 24., 24., 29., 27., 27., 23.,\n",
       "       24., 27., 30., 23., 22., 28., 22., 24., 29., 25., 23., 25., 25.,\n",
       "       23., 24., 27., 24., 27., 23., 30., 27., 30., 26., 25., 25., 26.,\n",
       "       26., 61., 26., 28., 26., 30., 23., 26., 22., 23., 61., 27., 23.,\n",
       "       30., 27., 31., 24., 22., 41., 26., 25., 26., 26., 41., 23., 26.,\n",
       "       26., 31., 26., 22., 26., 27., 36., 35., 31., 22., 29., 26., 30.,\n",
       "       27., 23., 28., 36., 33., 23., 27., 26., 26., 24., 22., 31., 23.,\n",
       "       26., 26., 26., 29., 26., 61., 28., 25., 26., 28., 26., 24., 26.,\n",
       "       41., 61., 28., 31., 29., 29., 23., 28., 27., 28., 31., 25., 27.,\n",
       "       26., 31., 27., 29., 25., 36., 26., 27., 28., 27., 28., 25., 27.,\n",
       "       33., 24., 25., 28., 25., 23., 23., 27., 26., 24., 22., 25., 26.,\n",
       "       24., 26., 29., 25., 23., 34., 23., 26., 26., 26., 24., 27., 23.,\n",
       "       24., 31., 25., 61., 26., 41., 32., 26., 27., 28., 41., 25., 33.,\n",
       "       27., 41., 28., 23., 29., 33., 29., 26., 29., 27., 34., 28., 26.,\n",
       "       25., 23., 26., 36., 26., 26., 26., 26., 27., 23., 23., 26., 27.,\n",
       "       32., 22., 25., 26., 33., 26., 26., 28., 25., 23., 22., 28., 29.,\n",
       "       27., 24., 25., 27., 34., 31., 31., 27., 27., 28., 30., 27., 22.,\n",
       "       30., 31., 22., 27., 31., 28., 27., 23., 25., 26., 22., 23., 26.,\n",
       "       27., 23., 26., 24., 27., 31., 25., 33., 33., 26., 35., 23., 24.,\n",
       "       26., 28., 24., 27., 26., 23., 30., 27., 30., 22., 22., 29., 33.,\n",
       "       22., 23., 28., 30., 23., 25., 23., 28., 33., 23., 31., 26., 25.,\n",
       "       26., 26., 25., 26., 30., 27., 31., 28., 61., 23., 27., 31., 22.,\n",
       "       27., 23., 25., 23., 23., 61., 27., 32., 25., 33., 26., 24., 22.,\n",
       "       23., 22., 23., 26., 26., 26., 31., 26., 28., 26., 27., 22., 22.,\n",
       "       28., 24., 26., 30., 23., 26., 31., 36., 26., 26., 25., 23., 26.,\n",
       "       23., 26., 23., 26., 29., 29., 23., 26., 29., 26., 23., 25., 30.,\n",
       "       30., 26., 30., 23., 26., 25., 23., 25., 31., 23., 27., 30., 25.,\n",
       "       30., 25., 26., 31., 25., 41., 27., 23., 23., 27., 23., 22., 28.,\n",
       "       22., 30., 26., 35., 26., 28., 33., 23., 27., 24., 23., 41., 26.,\n",
       "       26., 23., 24., 33., 23., 31., 28., 31., 22., 24., 28., 24., 28.,\n",
       "       27., 22., 27., 26., 33., 26., 23., 61., 23., 34., 25., 25., 25.,\n",
       "       31., 26., 26., 27., 27., 24., 30., 23., 24., 26., 35., 23., 25.,\n",
       "       28., 26., 30., 23., 23., 26., 26., 31., 25., 26., 25., 23., 26.,\n",
       "       25., 27., 36., 29., 26., 33., 31., 29., 26., 24., 28., 28., 25.,\n",
       "       35., 23., 33., 61., 30., 23., 26., 26., 27., 24., 30., 23., 23.,\n",
       "       36., 31., 31., 26., 61., 26., 33., 26., 25., 28., 26., 30., 26.,\n",
       "       26., 23., 24., 31., 28., 23., 24., 24., 22., 23., 26., 24., 24.,\n",
       "       23., 32., 23.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_model.fit(X_train_l2, y_train_l2[\"label_2\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label2 = knn_model.predict(X_test_contiguous)\n",
    "y_pred_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a977a-ca47-47b5-baa6-db12dd8d6f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65fdfaf7-c0b1-4239-ba7b-eb26abff0ff1",
   "metadata": {},
   "source": [
    "# Label_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b79a42-ae24-421b-9b9f-3e5bfc4c5e49",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "986adc72-7dc9-4a4f-b88e-09e5f3c0d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.8106666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.8533333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.8653333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.7306666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.8706666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.8706666666666667\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d229e-a3b8-40d9-8c6a-dfc0643242f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8269ac7-921f-45b5-b0bd-c3371933dcfa",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "450c81d8-53d4-426f-b492-616896a33c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Accuracy for KNN 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51538fad-55c7-4ef2-9f58-02d6ad60fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6eb1e765-777f-4568-a23c-f0724eda2b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9a0f3-2bfd-4ef1-a56e-85f01614d278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5a479-b96c-46d3-b58e-70e83c91a7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4adca5f8-c833-422d-8829-08ba993d9b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.47333333333333333\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069bac5-94ed-489c-834d-51e394ad555b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e75d91bb-88e6-477c-a427-bf45d889ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.8773333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.8773333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.8773333333333333\n",
      "Accuracy Score of Logistic Regression with solver saga 0.8773333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e79f8c-a6af-4309-b15b-fc59ea8f22e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fa039-ce91-482a-bed7-d0079a9c1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584d295-c1e7-4c0a-8014-1841e2019df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ccfc58-2e58-4092-8a72-bb193b9a1c5d",
   "metadata": {},
   "source": [
    "For label_3 we get best accuracy(0.87) when using the SVM with polynomial kernal function and Logistic Regression models.\n",
    "So we can use any of these methods to predict the values for test data set. I am going to use SVM with polynomial kernal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0260a0ca-1405-45a0-a76b-852e1e5dac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly',degree =2)\n",
    "clf.fit(X_train, y_train[\"label_3\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label3 = clf.predict(X_test_contiguous)\n",
    "y_pred_label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7404b-dc1a-4858-a617-662bc9337166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6715d-e6fe-4ab1-9d63-603cec30970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5632ce18-59e8-45af-945a-9521bd579607",
   "metadata": {},
   "source": [
    "# Label_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e8c75-52b6-4d24-b179-b4264fdefe56",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8abd250-10f8-4bbe-a944-f43b294fe6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.7093333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.06266666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.10666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.10666666666666667\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed0b6c-ba8c-4031-b897-3043d54dbe05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d99bf1-bead-4bf9-a6c7-c198d0d21db2",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34fea2dc-6a3b-4b97-a529-2a67e378f662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.676\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da144aea-9798-47d1-af73-17423452eadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1179495b-7445-4d47-a98e-b5d7ebac93ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.33066666666666666\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c786e-d39a-468e-83e7-8ccdc1a0f8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d58cc8ef-024f-4c4e-9849-4d60e79e9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.6866666666666666\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa4c01-095a-46a9-a88c-19f111809a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aa2a953-d7eb-40fa-a45a-f0120db64906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.10933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.10933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.10933333333333334\n",
      "Accuracy Score of Logistic Regression with solver saga 0.10933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6b09f-d785-4c9d-8533-765315730aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ef0ee-56e3-4648-bff6-d7d319ff56d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b07cf-7184-4c25-8413-401c125ccb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3206b4-da69-40a1-9926-8b956b72b072",
   "metadata": {},
   "source": [
    "For label_4 we get best accuracy(0.70933) when using the SVM with default settings.\n",
    "So we can use this methods to predict the values for test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcc0ea90-e4d8-4161-b0bc-0786bd0b77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2,  8,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  4,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  2,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6, 11,  5,  6,  6,  6,  6,  6,  6,  1,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  4,  6,  9,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  5, 10,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6, 11,  6,  6,  6,  2,  4,  6,  6,  6,  6,  6,  6,  3,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 10,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  4,  6,  6,\n",
       "        6,  6,  6, 10,  6, 10,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  2,  6,  6,  6, 11,  6,  6,  6,  6,  8,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  1,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,\n",
       "        5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 13,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  4,  6,  6, 12,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  6,  6, 12,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 11,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  7, 10,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  3,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  6,  6,  6,  6,  6,  7,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  9,  2,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6, 10,  6,  6,  6,  6,  6,  6,  6,  8,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  6,  6,  6, 11,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  1,\n",
       "        6,  6,  6,  6,  6,  1,  6,  6,  6,  6,  6,  6,  6,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  7,\n",
       "        4,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  9,  6, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,  6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train[\"label_4\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label4 = clf.predict(X_test_contiguous)\n",
    "y_pred_label4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589d0c1-acaf-4c6d-9e98-de206b4d9f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45799eab-29d9-4ec2-a06a-2ca904a46af0",
   "metadata": {},
   "source": [
    "# Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4512744f-1f4f-4bc7-b027-cd6293b6df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([pd.Series(test_df['ID']), pd.Series(y_pred_label1, name='label_1'), pd.Series(y_pred_label2, name='label_2'), pd.Series(y_pred_label3, name='label_3'), pd.Series(y_pred_label4, name='label_4')], axis=1)\n",
    "output_file_name = \"190541R_lab_2_II.csv\"\n",
    "final_df.to_csv(output_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e593181-e2ef-40c5-99e3-2467a1ef333c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
